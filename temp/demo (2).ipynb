{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ca68635-7d88-413a-b915-6e9693b745c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.5.9.post1.tar.gz (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from flash-attn) (2.3.1)\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (1.12.1)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (2.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (3.3)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (2.20.5)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (3.15.4)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (8.9.2.26)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (3.1.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (4.12.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.5.9.post1-cp310-cp310-linux_x86_64.whl size=120889689 sha256=5022ba11d48bf74926da9c16260f4ea2b9bb7f4e29bdb4bd6e1383ad1c55d16f\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/cc/ad/f6/7ccf0238790d6346e9fe622923a76ec218e890d356b9a2754a\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: einops, flash-attn\n",
      "Successfully installed einops-0.8.0 flash-attn-2.5.9.post1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0b3390d-1863-40aa-ab4d-ab64789b7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4b7d4aee4c4ea992e65ac6f9cb7d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "id2label = {\n",
    "    0: \"FIRST_PARTY_COLLECTION\",\n",
    "    1: \"THIRD_PARTY_COLLECTION\",\n",
    "    2: \"DATA_SECURITY\",\n",
    "    3: \"DATA_RETENTION\",\n",
    "    4: \"USER_ACCESS\",\n",
    "    5: \"USER_CHOICE\",\n",
    "    6: \"OTHER\"\n",
    "}\n",
    "\n",
    "label2id = {\n",
    "    \"FIRST_PARTY_COLLECTION\": 0 ,\n",
    "    \"THIRD_PARTY_COLLECTION\": 1,\n",
    "    \"DATA_SECURITY\": 2,\n",
    "    \"DATA_RETENTION\": 3,\n",
    "    \"USER_ACCESS\": 4,\n",
    "    \"USER_CHOICE\": 5,\n",
    "    \"OTHER\": 6\n",
    "}\n",
    "\n",
    "#config = PeftConfig.from_pretrained(\"shayan283/multilabel_classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"shayan283/multilabel_classification\", num_labels=7,\n",
    "            id2label=id2label, label2id=label2id, torch_dtype=torch.bfloat16, load_in_8bit=True,\n",
    "            attn_implementation=\"flash_attention_2\")\n",
    "# inference_model = PeftModel.from_pretrained(model, \"shayan283/multilabel_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d5a441b-76b2-439d-8a44-a6ce0f27fdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"shayan283/multilabel_classification\")\n",
    "# model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71b52193-7b6a-47a9-b977-430986cf12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import PretrainedConfig, pipeline\n",
    "text_classification_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1792ad5-79c1-480e-9019-0c7642a2169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: FIRST_PARTY_COLLECTION, Score: 0.9993\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"To fulfill requests for products, services, Platform functionality, support and information for internal operations, including troubleshooting, data analysis, testing, research, statistical, and survey purposes and to solicit your feedback.\n",
    "To customize the content you see when you use the Platform. For example, we may provide you with services based on the country settings you have chosen or show you content that is similar to content that you have liked or interacted with.\n",
    "To send promotional materials from us or on behalf of our affiliates and trusted third parties.\n",
    "To improve and develop our Platform and conduct product development.\"\"\"\n",
    "\n",
    "predictions = text_classification_pipeline(text)\n",
    "for prediction in predictions:\n",
    "    print(f\"Label: {prediction['label']}, Score: {prediction['score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
